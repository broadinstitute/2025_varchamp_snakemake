{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFP-Filtered Classification Testing\n",
    "\n",
    "Step-by-step testing of the GFP filtering approach for CCM2_Val53Ile classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target allele: CCM2_Val53Ile\n",
      "Target batches: ['2025_06_10_Batch_18']\n",
      "Input paths:\n",
      "  ‚úÖ ../outputs/batch_profiles/2025_06_10_Batch_18/profiles_tcdropped_filtered_var_mad_outlier_featselect_filtcells.parquet\n"
     ]
    }
   ],
   "source": [
    "# Set up variables\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_rel, ttest_ind, shapiro, wilcoxon\n",
    "\n",
    "# Add utils path\n",
    "sys.path.append(\"..\")\n",
    "from utils import find_feat_cols, find_meta_cols, remove_nan_infs_columns\n",
    "\n",
    "# Set variables\n",
    "TARGET_ALLELE = \"CCM2_Val53Ile\"\n",
    "TARGET_BATCHES = [\"2025_06_10_Batch_18\"] ## , \"2025_06_10_Batch_19\"\n",
    "INPUT_DIR = \"../outputs/batch_profiles/\"\n",
    "CC_THRESHOLD = 20\n",
    "MIN_CELLS_PER_WELL = 100\n",
    "GFP_INTENSITY_COLUMN = \"Cells_Intensity_IntegratedIntensity_GFP\" ## Cells_Intensity_MeanIntensity_GFP is another option\n",
    "\n",
    "# Input file paths\n",
    "input_paths = [\n",
    "    os.path.join(INPUT_DIR, batch, \"profiles_tcdropped_filtered_var_mad_outlier_featselect_filtcells.parquet\")\n",
    "    for batch in TARGET_BATCHES\n",
    "]\n",
    "# Input file paths\n",
    "input_orig_paths = [\n",
    "    os.path.join(INPUT_DIR, batch, \"profiles_tcdropped_filtered_var_mad_outlier.parquet\")\n",
    "    for batch in TARGET_BATCHES\n",
    "]\n",
    "\n",
    "print(f\"Target allele: {TARGET_ALLELE}\")\n",
    "print(f\"Target batches: {TARGET_BATCHES}\")\n",
    "print(f\"Input paths:\")\n",
    "for path in input_paths:\n",
    "    exists = \"‚úÖ\" if os.path.exists(path) else \"‚ùå\"\n",
    "    print(f\"  {exists} {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading both batches...\n",
      "Loading 2025_06_10_Batch_18...\n",
      "Combining dataframes...\n",
      "\n",
      "[LOADING] Total cells loaded: 1,353,285 (5.1s total, 5.1s combine)\n"
     ]
    }
   ],
   "source": [
    "# Load both batches efficiently\n",
    "print(\"Loading both batches...\")\n",
    "start_time = time.time()\n",
    "\n",
    "dframes = []\n",
    "total_loaded = 0\n",
    "\n",
    "for i, path in enumerate(input_paths):\n",
    "    print(f\"Loading {TARGET_BATCHES[i]}...\")\n",
    "    batch_start = time.time()\n",
    "    \n",
    "    # Load with Cell ID creation\n",
    "    df_batch = (\n",
    "        pl.scan_parquet(path)\n",
    "        .with_columns(\n",
    "            pl.concat_str([\n",
    "                \"Metadata_Plate\",\n",
    "                \"Metadata_well_position\",\n",
    "                \"Metadata_ImageNumber\", \n",
    "                \"Metadata_ObjectNumber\"\n",
    "            ], separator=\"_\").alias(\"Metadata_CellID\")\n",
    "        )\n",
    "        # .collect()\n",
    "        # .to_pandas()\n",
    "    )\n",
    "\n",
    "    # Load with Cell ID creation\n",
    "    df_batch_orig = (\n",
    "        pl.scan_parquet(input_orig_paths[i])\n",
    "        .with_columns(\n",
    "            pl.concat_str([\n",
    "                \"Metadata_Plate\",\n",
    "                \"Metadata_well_position\",\n",
    "                \"Metadata_ImageNumber\", \n",
    "                \"Metadata_ObjectNumber\"\n",
    "            ], separator=\"_\").alias(\"Metadata_CellID\")\n",
    "        )\n",
    "        .select(pl.col([\"Metadata_CellID\", \"Cells_Intensity_IntegratedIntensity_GFP\"]))\n",
    "        # .collect()\n",
    "        # .to_pandas()\n",
    "    )\n",
    "    \n",
    "    df_batch = df_batch.join(\n",
    "        df_batch_orig, on=\"Metadata_CellID\", how=\"left\"\n",
    "    ).with_columns(\n",
    "        pl.lit(TARGET_BATCHES[i]).alias(\"Metadata_Source_Batch\")\n",
    "    )\n",
    "    dframes.append(df_batch)\n",
    "    batch_time = time.time() - batch_start\n",
    "    \n",
    "    # print(f\"  - {TARGET_BATCHES[i]}: {len(df_batch):,} cells ({batch_time:.1f}s)\")\n",
    "    # total_loaded += len(df_batch)\n",
    "\n",
    "# .collect().to_pandas()\n",
    "\n",
    "# Combine dataframes\n",
    "print(\"Combining dataframes...\")\n",
    "combine_start = time.time()\n",
    "df_combined = pl.concat(dframes, how=\"diagonal\").collect().to_pandas()\n",
    "combine_time = time.time() - combine_start\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_loaded = df_combined.shape[0]\n",
    "print(f\"\\n[LOADING] Total cells loaded: {total_loaded:,} ({total_time:.1f}s total, {combine_time:.1f}s combine)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key columns check:\n",
      "  ‚úÖ Metadata_symbol\n",
      "  ‚úÖ Metadata_gene_allele\n",
      "  ‚úÖ Metadata_node_type\n",
      "  ‚úÖ Metadata_well_position\n",
      "  ‚úÖ Metadata_Plate\n",
      "  ‚úÖ Cells_Intensity_IntegratedIntensity_GFP\n"
     ]
    }
   ],
   "source": [
    "# Check for key columns\n",
    "key_columns = [\"Metadata_symbol\", \"Metadata_gene_allele\", \"Metadata_node_type\", \n",
    "               \"Metadata_well_position\", \"Metadata_Plate\", \"Cells_Intensity_IntegratedIntensity_GFP\"]\n",
    "\n",
    "print(\"\\nKey columns check:\")\n",
    "for col in key_columns:\n",
    "    exists = \"‚úÖ\" if col in df_combined.columns else \"‚ùå\"\n",
    "    print(f\"  {exists} {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing and Gene Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add control annotation\n",
    "# def add_control_annot(dframe: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Add control annotation column\"\"\"\n",
    "#     def control_type_helper(node_type: str):\n",
    "#         if node_type in [\"TC\", \"NC\", \"PC\"]:\n",
    "#             return True\n",
    "#         elif node_type in [\"disease_wt\", \"allele\", \"cPC\", \"cNC\"]:\n",
    "#             return False\n",
    "#         else:\n",
    "#             return None\n",
    "    \n",
    "#     if \"Metadata_control\" not in dframe.columns:\n",
    "#         dframe[\"Metadata_control\"] = dframe[\"Metadata_node_type\"].apply(control_type_helper)\n",
    "    \n",
    "#     return dframe\n",
    "\n",
    "# # Basic preprocessing\n",
    "# print(\"[PREPROCESSING] Basic cleanup...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Filter rows with NaN metadata\n",
    "# initial_count = len(df_combined)\n",
    "# df_combined = df_combined[~df_combined[\"Metadata_well_position\"].isna()]\n",
    "# df_combined = add_control_annot(df_combined)\n",
    "# df_combined = df_combined[~df_combined[\"Metadata_control\"].isna()]\n",
    "\n",
    "# cleanup_time = time.time() - start_time\n",
    "# print(f\"Cleaned up in {cleanup_time:.1f}s: {initial_count:,} ‚Üí {len(df_combined):,} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GENE_FILTER] Filtering to CCM2 gene...\n",
      "CCM2 cells: 112,862 (8.3% of total)\n",
      "\n",
      "CCM2 Gene alleles:\n",
      "Metadata_gene_allele\n",
      "CCM2_Val120Ile    12214\n",
      "CCM2_Phe270Leu    11902\n",
      "CCM2_Ser413Leu    11402\n",
      "CCM2_Val53Ile     11348\n",
      "CCM2_Leu198Arg    11080\n",
      "CCM2_Leu212Pro    10917\n",
      "CCM2_Asn327Ser    10762\n",
      "CCM2_Leu195Arg    10631\n",
      "CCM2_Met1Val       9597\n",
      "CCM2_Thr406Met     8384\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CCM2 Node types:\n",
      "Metadata_node_type\n",
      "allele        108237\n",
      "disease_wt      4625\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target allele 'CCM2_Val53Ile' exists: ‚úÖ\n",
      "  CCM2_Val53Ile: 11,348 cells\n"
     ]
    }
   ],
   "source": [
    "# Filter to CCM2 gene and target batches\n",
    "print(\"[GENE_FILTER] Filtering to CCM2 gene...\")\n",
    "df_gene = df_combined[df_combined[\"Metadata_symbol\"] == \"CCM2\"].copy()\n",
    "print(f\"CCM2 cells: {len(df_gene):,} ({100*len(df_gene)/total_loaded:.1f}% of total)\")\n",
    "\n",
    "# Check gene alleles and node types in CCM2 data\n",
    "print(\"\\nCCM2 Gene alleles:\")\n",
    "gene_allele_counts = df_gene[\"Metadata_gene_allele\"].value_counts()\n",
    "print(gene_allele_counts.head(10))\n",
    "\n",
    "print(\"\\nCCM2 Node types:\")\n",
    "node_type_counts = df_gene[\"Metadata_node_type\"].value_counts()\n",
    "print(node_type_counts)\n",
    "\n",
    "# Check if our target allele exists\n",
    "target_exists = TARGET_ALLELE in gene_allele_counts.index\n",
    "print(f\"\\nTarget allele '{TARGET_ALLELE}' exists: {'‚úÖ' if target_exists else '‚ùå'}\")\n",
    "if target_exists:\n",
    "    print(f\"  {TARGET_ALLELE}: {gene_allele_counts[TARGET_ALLELE]:,} cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Separate Reference and Variant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental data (non-control): 112,862 cells\n",
      "\n",
      "Reference (disease_wt): 4,625 cells\n",
      "Variant (CCM2_Val53Ile): 11,348 cells\n",
      "\n",
      "Reference well breakdown:\n",
      "Metadata_Source_Batch  Metadata_Plate              Metadata_well_position\n",
      "2025_06_10_Batch_18    2025_06_02_B18A8A10R1_P2T1  A19                       453\n",
      "                                                   I21                       305\n",
      "                       2025_06_02_B18A8A10R1_P2T2  A19                       808\n",
      "                                                   I21                       480\n",
      "                       2025_06_02_B18A8A10R1_P2T3  A19                       995\n",
      "                                                   I21                       457\n",
      "                       2025_06_02_B18A8A10R1_P2T4  A19                       699\n",
      "                                                   I21                       428\n",
      "dtype: int64\n",
      "\n",
      "Variant well breakdown:\n"
     ]
    }
   ],
   "source": [
    "# Split into experimental data (variant vs reference)\n",
    "df_exp = df_gene\n",
    "print(f\"Experimental data (non-control): {len(df_exp):,} cells\")\n",
    "\n",
    "# Separate reference and variant alleles\n",
    "df_variant = df_exp[df_exp[\"Metadata_gene_allele\"] == TARGET_ALLELE].copy()\n",
    "df_reference = df_exp[df_exp[\"Metadata_node_type\"] == \"disease_wt\"].copy()\n",
    "\n",
    "print(f\"\\nReference (disease_wt): {len(df_reference):,} cells\")\n",
    "print(f\"Variant ({TARGET_ALLELE}): {len(df_variant):,} cells\")\n",
    "\n",
    "if len(df_reference) > 0:\n",
    "    print(\"\\nReference well breakdown:\")\n",
    "    ref_wells = df_reference.groupby([\"Metadata_Source_Batch\", \"Metadata_Plate\", \"Metadata_well_position\"]).size()\n",
    "    print(ref_wells.head(10))\n",
    "\n",
    "if len(df_variant) > 0:\n",
    "    print(\"\\nVariant well breakdown:\")\n",
    "    var_wells = df_variant.groupby([\"Metadata_Source_Batch\", \"Metadata_Plate\", \"Metadata_well_position\"]).size()\n",
    "    # print(var_wells.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test GFP Range Optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GFP range optimization function with expanded ranges and ratio constraint\n",
    "def find_optimal_gfp_range_fast(ref_gfp: np.ndarray, var_gfp: np.ndarray, \n",
    "                               min_cells_per_well: int = 100, max_ratio: float = 3.0):\n",
    "    \"\"\"Ultra-fast vectorized GFP range optimization with expanded ranges and ratio constraint\"\"\"\n",
    "    # Expanded quantile range testing: from 10%-90% down to 30%-70%\n",
    "    quantile_pairs = [\n",
    "        (0.1, 0.9), (0.12, 0.88), (0.15, 0.85), (0.17, 0.83), (0.2, 0.8),\n",
    "        (0.22, 0.78), (0.25, 0.75), (0.27, 0.73), (0.3, 0.7)\n",
    "    ]\n",
    "    \n",
    "    # Vectorized quantile calculation for all ranges\n",
    "    all_quantiles = [q for pair in quantile_pairs for q in pair]\n",
    "    ref_qs = np.quantile(ref_gfp, all_quantiles)\n",
    "    var_qs = np.quantile(var_gfp, all_quantiles)\n",
    "    \n",
    "    best_range = None\n",
    "    max_total_cells = 0\n",
    "    best_quantile_info = \"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test each quantile pair\n",
    "    for i, (low_q, high_q) in enumerate(quantile_pairs):\n",
    "        # Get quantile boundaries for this pair\n",
    "        ref_low = ref_qs[i*2]\n",
    "        ref_high = ref_qs[i*2 + 1] \n",
    "        var_low = var_qs[i*2]\n",
    "        var_high = var_qs[i*2 + 1]\n",
    "        \n",
    "        # Find overlapping range\n",
    "        range_min = max(ref_low, var_low)\n",
    "        range_max = min(ref_high, var_high)\n",
    "        \n",
    "        # Skip if invalid range\n",
    "        if range_min >= range_max:\n",
    "            results.append((f\"{int(low_q*100)}-{int(high_q*100)}%\", 0, 0, 0, \"Invalid range\", \"N/A\"))\n",
    "            continue\n",
    "            \n",
    "        # Vectorized cell counting\n",
    "        ref_mask = (ref_gfp >= range_min) & (ref_gfp <= range_max)\n",
    "        var_mask = (var_gfp >= range_min) & (var_gfp <= range_max)\n",
    "        ref_count = np.sum(ref_mask)\n",
    "        var_count = np.sum(var_mask)\n",
    "        \n",
    "        # Calculate sample size ratio\n",
    "        if ref_count == 0 or var_count == 0:\n",
    "            ratio_status = \"Zero samples\"\n",
    "        else:\n",
    "            ratio = max(ref_count, var_count) / min(ref_count, var_count)\n",
    "            ratio_status = f\"Ratio: {ratio:.1f}\" if ratio <= max_ratio else f\"Ratio: {ratio:.1f} (>3x)\"\n",
    "        \n",
    "        results.append((f\"{int(low_q*100)}-{int(high_q*100)}%\", ref_count, var_count, \n",
    "                       ref_count + var_count, f\"GFP: {range_min:.1f}-{range_max:.1f}\", ratio_status))\n",
    "        \n",
    "        # Check minimum requirements and ratio constraint\n",
    "        if (ref_count >= min_cells_per_well and var_count >= min_cells_per_well and\n",
    "            ref_count > 0 and var_count > 0):\n",
    "            \n",
    "            ratio = max(ref_count, var_count) / min(ref_count, var_count)\n",
    "            \n",
    "            if ratio <= max_ratio:  # Ratio constraint\n",
    "                total_cells = ref_count + var_count\n",
    "                if total_cells > max_total_cells:\n",
    "                    max_total_cells = total_cells\n",
    "                    best_range = (range_min, range_max, ref_count, var_count)\n",
    "                    best_quantile_info = f\"{int(low_q*100)}%-{int(high_q*100)}%\"\n",
    "    \n",
    "    # Show all results\n",
    "    # print(\"GFP Range Optimization Results (with ratio constraint ‚â§3x):\")\n",
    "    # print(\"Quantile Range | Ref Cells | Var Cells | Total | GFP Range      | Sample Ratio\")\n",
    "    # print(\"-\" * 90)\n",
    "    # for quantile, ref_c, var_c, total, gfp_range, ratio_info in results:\n",
    "    #     # Check if this meets all criteria\n",
    "    #     meets_min = ref_c >= min_cells_per_well and var_c >= min_cells_per_well\n",
    "    #     meets_ratio = \"Ratio:\" in ratio_info and not \"(>3x)\" in ratio_info if ref_c > 0 and var_c > 0 else False\n",
    "    #     status = \"‚úÖ\" if (meets_min and meets_ratio) else \"‚ùå\"\n",
    "    #     print(f\"{status} {quantile:>12} | {ref_c:>8} | {var_c:>8} | {total:>5} | {gfp_range:>14} | {ratio_info}\")\n",
    "    \n",
    "    if best_range is None:\n",
    "        return None, None, 0, 0, \"NO_SUITABLE_RANGE\"\n",
    "    \n",
    "    return best_range[0], best_range[1], best_range[2], best_range[3], best_quantile_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY ===\n",
      "Total cells loaded: 1,353,285\n",
      "CCM2 cells: 112,862 (8.3%)\n",
      "Reference cells: 4,625\n",
      "Variant cells (CCM2_Val53Ile): 11,348\n",
      "\n",
      "‚úÖ Data looks good for classification!\n",
      "  Plate 2025_06_02_B18A8A10R1_P2T1: 2 ref √ó 2 var = 4 pairs\n",
      "  Plate 2025_06_02_B18A8A10R1_P2T2: 2 ref √ó 2 var = 4 pairs\n",
      "  Plate 2025_06_02_B18A8A10R1_P2T3: 2 ref √ó 2 var = 4 pairs\n",
      "  Plate 2025_06_02_B18A8A10R1_P2T4: 2 ref √ó 2 var = 4 pairs\n",
      "\n",
      "Total potential well pairs for classification: 16\n",
      "\n",
      "üöÄ Ready to proceed with full classification pipeline!\n"
     ]
    }
   ],
   "source": [
    "# Summary of findings\n",
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"Total cells loaded: {total_loaded:,}\")\n",
    "print(f\"CCM2 cells: {len(df_gene):,} ({100*len(df_gene)/total_loaded:.1f}%)\")\n",
    "print(f\"Reference cells: {len(df_reference):,}\")\n",
    "print(f\"Variant cells ({TARGET_ALLELE}): {len(df_variant):,}\")\n",
    "\n",
    "if len(df_reference) > 0 and len(df_variant) > 0:\n",
    "    print(f\"\\n‚úÖ Data looks good for classification!\")\n",
    "    \n",
    "    # Count potential well pairs\n",
    "    common_plates = list(set(df_reference[\"Metadata_Plate\"].unique()) & \n",
    "                        set(df_variant[\"Metadata_Plate\"].unique()))\n",
    "    \n",
    "    total_pairs = 0\n",
    "    for plate in common_plates:\n",
    "        ref_wells_plate = len(df_reference[df_reference[\"Metadata_Plate\"] == plate][\"Metadata_well_position\"].unique())\n",
    "        var_wells_plate = len(df_variant[df_variant[\"Metadata_Plate\"] == plate][\"Metadata_well_position\"].unique())\n",
    "        pairs_plate = ref_wells_plate * var_wells_plate\n",
    "        total_pairs += pairs_plate\n",
    "        print(f\"  Plate {plate}: {ref_wells_plate} ref √ó {var_wells_plate} var = {pairs_plate} pairs\")\n",
    "    \n",
    "    print(f\"\\nTotal potential well pairs for classification: {total_pairs}\")\n",
    "    print(f\"\\nüöÄ Ready to proceed with full classification pipeline!\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Missing reference or variant data - check allele names and data quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported classification functions from classify_gfp_filtered.py\n"
     ]
    }
   ],
   "source": [
    "# Import classification functions\n",
    "import importlib.util\n",
    "# Load functions from classify_gfp_filtered.py\n",
    "spec = importlib.util.spec_from_file_location(\"classify_gfp_filtered\", \"./classify_gfp_filtered.py\")\n",
    "classify_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(classify_module)\n",
    "\n",
    "# Import specific functions we need\n",
    "from classify import (\n",
    "    drop_low_cc_wells,\n",
    "    # find_optimal_gfp_range_fast,\n",
    "    # get_classifier_features\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Successfully imported classification functions from classify_gfp_filtered.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL_COUNT_FILTER] Applying cell count threshold...\n",
      "Combined experimental data: 15,973 cells\n",
      "After CC filtering (‚â•20 cells/well): 15,973 cells (0.04s)\n",
      "Cells removed: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Apply cell count filter\n",
    "print(\"[CELL_COUNT_FILTER] Applying cell count threshold...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Combine reference and variant data\n",
    "df_exp_combined = pd.concat([df_reference, df_variant], ignore_index=True)\n",
    "print(f\"Combined experimental data: {len(df_exp_combined):,} cells\")\n",
    "\n",
    "# Apply cell count filtering\n",
    "df_cc_filtered = df_exp_combined #drop_low_cc_wells(df_exp_combined, CC_THRESHOLD, log_file=None)\n",
    "cc_filter_time = time.time() - start_time\n",
    "\n",
    "print(f\"After CC filtering (‚â•{CC_THRESHOLD} cells/well): {len(df_cc_filtered):,} cells ({cc_filter_time:.2f}s)\")\n",
    "print(f\"Cells removed: {len(df_exp_combined) - len(df_cc_filtered):,} ({100*(len(df_exp_combined) - len(df_cc_filtered))/len(df_exp_combined):.1f}%)\")\n",
    "\n",
    "# Split back into reference and variant after filtering\n",
    "df_reference_cc = df_cc_filtered[df_cc_filtered[\"Metadata_node_type\"] == \"disease_wt\"].copy()\n",
    "df_variant_cc = df_cc_filtered[df_cc_filtered[\"Metadata_gene_allele\"] == TARGET_ALLELE].copy()\n",
    "\n",
    "print(f\"CC-filtered Reference: {len(df_reference_cc):,} cells\")\n",
    "print(f\"CC-filtered Variant: {len(df_variant_cc):,} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>t_stat</th><th>p_val</th><th>cohen_d</th><th>Gene</th><th>Variant</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>10.759059</td><td>0.001717</td><td>4.965372</td><td>&quot;CCM2&quot;</td><td>&quot;CCM2_Val53Ile&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ t_stat    ‚îÜ p_val    ‚îÜ cohen_d  ‚îÜ Gene ‚îÜ Variant       ‚îÇ\n",
       "‚îÇ ---       ‚îÜ ---      ‚îÜ ---      ‚îÜ ---  ‚îÜ ---           ‚îÇ\n",
       "‚îÇ f64       ‚îÜ f64      ‚îÜ f64      ‚îÜ str  ‚îÜ str           ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 10.759059 ‚îÜ 0.001717 ‚îÜ 4.965372 ‚îÜ CCM2 ‚îÜ CCM2_Val53Ile ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_exp_combined_well = pl.DataFrame(\n",
    "    pd.concat([df_reference_cc, df_variant_cc], axis=0)\n",
    ").group_by(\n",
    "    [\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_gene_allele\"]\n",
    ").agg(\n",
    "    pl.col(col).median().alias(col)\n",
    "    for col in df_exp_combined.columns\n",
    "    if not col.startswith(\"Metadata_\")\n",
    ").unique() # .filter(pl.col(\"Metadata_gene_allele\").is_in(balanced_class_alleles))\n",
    "\n",
    "display(paired_ttest(\n",
    "    df_exp_combined_well.filter(pl.col(\"Metadata_Well\").is_in([\"I21\", \"M19\"])).to_pandas(), \n",
    "    \"CCM2\", TARGET_ALLELE, GFP_INTENSITY_COLUMN\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paired t-test to detect difference in cell count and gfp intensity\n",
    "def paired_ttest(dat, reference: str, var: str, value: str, min_num_rep: int=3):\n",
    "    # pivot to wide: one row per plate\n",
    "    wide_gfp = dat.pivot(index=\"Metadata_Plate\",\n",
    "                        columns=\"Metadata_gene_allele\",\n",
    "                        values=value)\n",
    "    # drop any plate that doesn‚Äôt have both measurements\n",
    "    wide_gfp = wide_gfp.dropna(subset=[reference, var])\n",
    "    if wide_gfp.shape[0] >= min_num_rep:\n",
    "        # now run paired t-test\n",
    "        t_stat, p_val = ttest_rel(wide_gfp[var].astype(float), wide_gfp[reference].astype(float))\n",
    "    else:\n",
    "        t_stat, p_val = None, None\n",
    "\n",
    "    # Calculate Cohen's d\n",
    "    mean_diff = np.mean(wide_gfp[var]) - np.mean(wide_gfp[reference])\n",
    "    pooled_std = np.sqrt((np.std(wide_gfp[var], ddof=1) ** 2 + np.std(wide_gfp[reference], ddof=1) ** 2) / 2)\n",
    "    cohen_d = mean_diff / pooled_std\n",
    "\n",
    "    summary_df = pl.DataFrame(\n",
    "        {\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_val\": p_val,\n",
    "            \"cohen_d\": cohen_d\n",
    "        }\n",
    "    )\n",
    "    summary_df = summary_df.with_columns(\n",
    "        pl.lit(reference).alias(\"Gene\"), pl.lit(var).alias(\"Variant\")\n",
    "    )\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WELL_PAIRS] Identifying well pairs...\n",
      "Total well pairs identified: 16\n",
      "Testing on first 5 well pairs:\n",
      "\n",
      "[1/5] Testing plate 2025_06_02_B18A8A10R1_P2T1, ref A19 vs var M19\n",
      "  Original cells: 453 ref, 1025 var\n",
      "\n",
      "[2/5] Testing plate 2025_06_02_B18A8A10R1_P2T1, ref A19 vs var C23\n",
      "  Original cells: 453 ref, 1321 var\n",
      "\n",
      "[3/5] Testing plate 2025_06_02_B18A8A10R1_P2T1, ref I21 vs var M19\n",
      "  Original cells: 305 ref, 1025 var\n",
      "\n",
      "[4/5] Testing plate 2025_06_02_B18A8A10R1_P2T1, ref I21 vs var C23\n",
      "  Original cells: 305 ref, 1321 var\n",
      "\n",
      "[5/5] Testing plate 2025_06_02_B18A8A10R1_P2T2, ref A19 vs var M19\n",
      "  Original cells: 808 ref, 1465 var\n",
      "\n",
      "[6/5] Testing plate 2025_06_02_B18A8A10R1_P2T2, ref A19 vs var C23\n",
      "  Original cells: 808 ref, 1414 var\n",
      "\n",
      "[7/5] Testing plate 2025_06_02_B18A8A10R1_P2T2, ref I21 vs var M19\n",
      "  Original cells: 480 ref, 1465 var\n",
      "\n",
      "[8/5] Testing plate 2025_06_02_B18A8A10R1_P2T2, ref I21 vs var C23\n",
      "  Original cells: 480 ref, 1414 var\n",
      "\n",
      "[9/5] Testing plate 2025_06_02_B18A8A10R1_P2T3, ref I21 vs var C23\n",
      "  Original cells: 457 ref, 1603 var\n",
      "\n",
      "[10/5] Testing plate 2025_06_02_B18A8A10R1_P2T3, ref I21 vs var M19\n",
      "  Original cells: 457 ref, 1561 var\n",
      "\n",
      "[11/5] Testing plate 2025_06_02_B18A8A10R1_P2T3, ref A19 vs var C23\n",
      "  Original cells: 995 ref, 1603 var\n",
      "\n",
      "[12/5] Testing plate 2025_06_02_B18A8A10R1_P2T3, ref A19 vs var M19\n",
      "  Original cells: 995 ref, 1561 var\n",
      "\n",
      "[13/5] Testing plate 2025_06_02_B18A8A10R1_P2T4, ref I21 vs var C23\n",
      "  Original cells: 428 ref, 1534 var\n",
      "\n",
      "[14/5] Testing plate 2025_06_02_B18A8A10R1_P2T4, ref I21 vs var M19\n",
      "  Original cells: 428 ref, 1425 var\n",
      "\n",
      "[15/5] Testing plate 2025_06_02_B18A8A10R1_P2T4, ref A19 vs var C23\n",
      "  Original cells: 699 ref, 1534 var\n",
      "\n",
      "[16/5] Testing plate 2025_06_02_B18A8A10R1_P2T4, ref A19 vs var M19\n",
      "  Original cells: 699 ref, 1425 var\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Get well pairs and test GFP filtering on limited pairs\n",
    "print(\"[WELL_PAIRS] Identifying well pairs...\")\n",
    "\n",
    "# Get well pairs\n",
    "well_pairs = []\n",
    "plates = list(set(df_reference_cc[\"Metadata_Plate\"].unique()) & \n",
    "              set(df_variant_cc[\"Metadata_Plate\"].unique()))\n",
    "\n",
    "for plate in plates:\n",
    "    ref_wells = df_reference_cc[df_reference_cc[\"Metadata_Plate\"] == plate][\"Metadata_well_position\"].unique()\n",
    "    var_wells = df_variant_cc[df_variant_cc[\"Metadata_Plate\"] == plate][\"Metadata_well_position\"].unique()\n",
    "    \n",
    "    for ref_well in ref_wells:\n",
    "        for var_well in var_wells:\n",
    "            well_pairs.append((plate, ref_well, var_well))\n",
    "\n",
    "print(f\"Total well pairs identified: {len(well_pairs)}\")\n",
    "\n",
    "# Test on first 5 pairs for speed\n",
    "TEST_PAIRS = 5\n",
    "test_pairs = well_pairs#[:TEST_PAIRS]\n",
    "print(f\"Testing on first {TEST_PAIRS} well pairs:\")\n",
    "\n",
    "# df_exp_combined\n",
    "\n",
    "gfp_filtered_results = []\n",
    "\n",
    "for i, (plate, ref_well, var_well) in enumerate(test_pairs):\n",
    "    print(f\"\\n[{i+1}/{TEST_PAIRS}] Testing plate {plate}, ref {ref_well} vs var {var_well}\")\n",
    "    \n",
    "    # Get well data\n",
    "    ref_well_data = df_reference_cc[\n",
    "        (df_reference_cc[\"Metadata_Plate\"] == plate) & \n",
    "        (df_reference_cc[\"Metadata_well_position\"] == ref_well)\n",
    "    ].copy()\n",
    "    \n",
    "    var_well_data = df_variant_cc[\n",
    "        (df_variant_cc[\"Metadata_Plate\"] == plate) & \n",
    "        (df_variant_cc[\"Metadata_well_position\"] == var_well)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"  Original cells: {len(ref_well_data)} ref, {len(var_well_data)} var\")\n",
    "\n",
    "    # df_exp_combined_well = pl.DataFrame(\n",
    "    #     pd.concat([ref_well_data, var_well_data], axis=0)\n",
    "    # ).group_by(\n",
    "    #     [\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_gene_allele\"]\n",
    "    # ).agg(\n",
    "    #     pl.col(col).median().alias(col)\n",
    "    #     for col in df_exp_combined.columns\n",
    "    #     if not col.startswith(\"Metadata_\")\n",
    "    # ).unique() # .filter(pl.col(\"Metadata_gene_allele\").is_in(balanced_class_alleles))\n",
    "\n",
    "    # display(df_exp_combined_well)\n",
    "    # display(paired_ttest(\n",
    "    #     df_exp_combined_well.to_pandas(), \n",
    "    #     \"CCM2\", TARGET_ALLELE, GFP_INTENSITY_COLUMN\n",
    "    # ))\n",
    "    \n",
    "    # Test GFP filtering\n",
    "    ref_gfp_values = ref_well_data[\"Cells_Intensity_IntegratedIntensity_GFP\"].values\n",
    "    var_gfp_values = var_well_data[\"Cells_Intensity_IntegratedIntensity_GFP\"].values\n",
    "    # print(ref_gfp_values, var_gfp_values)\n",
    "    \n",
    "    gfp_min, gfp_max, ref_filtered, var_filtered, quantile_info = find_optimal_gfp_range_fast(\n",
    "        ref_gfp_values, var_gfp_values, MIN_CELLS_PER_WELL\n",
    "    )\n",
    "    \n",
    "    # Apply GFP filtering\n",
    "    ref_filtered = ref_well_data[\n",
    "        (ref_well_data[GFP_INTENSITY_COLUMN] >= gfp_min) & \n",
    "        (ref_well_data[GFP_INTENSITY_COLUMN] <= gfp_max)\n",
    "    ].copy()\n",
    "    var_filtered = var_well_data[\n",
    "        (var_well_data[GFP_INTENSITY_COLUMN] >= gfp_min) & \n",
    "        (var_well_data[GFP_INTENSITY_COLUMN] <= gfp_max)\n",
    "    ].copy()\n",
    "\n",
    "    gfp_filtered_results.append(ref_filtered)\n",
    "    gfp_filtered_results.append(var_filtered)\n",
    "\n",
    "    # sns.boxplot(data=pd.concat([var_filtered, ref_filtered],axis=0), \n",
    "    #             x=\"Metadata_gene_allele\",\n",
    "    #             y=GFP_INTENSITY_COLUMN)\n",
    "    # plt.show()\n",
    "    \n",
    "    # # Prepare for classification\n",
    "    # ref_filtered[\"Label\"] = 1  # Reference = 1\n",
    "    # var_filtered[\"Label\"] = 0  # Variant = 0\n",
    "    \n",
    "    # combined_data = pd.concat([ref_filtered, var_filtered], ignore_index=True)\n",
    "    # Stratify by plate for training/testing  \n",
    "    # df_train, df_test = stratify_by_plate_gfp(combined_data, plate)\n",
    "    \n",
    "    # if gfp_min is not None:\n",
    "    #     gfp_filtered_results.append({\n",
    "    #         'pair_id': f\"{plate}_{ref_well}_vs_{var_well}\",\n",
    "    #         'plate': plate,\n",
    "    #         'ref_well': ref_well,\n",
    "    #         'var_well': var_well,\n",
    "    #         'ref_orig': len(ref_well_data),\n",
    "    #         'var_orig': len(var_well_data),\n",
    "            # 'ref_filtered': ref_filtered,\n",
    "            # 'var_filtered': var_filtered,\n",
    "            # 'gfp_min': gfp_min,\n",
    "            # 'gfp_max': gfp_max,\n",
    "            # 'quantile_range': quantile_info,\n",
    "            # 'status': 'SUCCESS'\n",
    "    #     })\n",
    "    #     # print(f\"  ‚úÖ GFP filtered: {ref_filtered} ref, {var_filtered} var ({quantile_info}, GFP: {gfp_min:.1f}-{gfp_max:.1f})\")\n",
    "    # else:\n",
    "    #     gfp_filtered_results.append({\n",
    "    #         'pair_id': f\"{plate}_{ref_well}_vs_{var_well}\",\n",
    "    #         'plate': plate,\n",
    "    #         'ref_well': ref_well,\n",
    "    #         'var_well': var_well,\n",
    "    #         'ref_orig': len(ref_well_data),\n",
    "    #         'var_orig': len(var_well_data),\n",
    "    #         'ref_filtered': 0,\n",
    "    #         'var_filtered': 0,\n",
    "    #         'gfp_min': None,\n",
    "    #         'gfp_max': None,\n",
    "    #         'quantile_range': 'FAILED',\n",
    "    #         'status': 'NO_SUITABLE_RANGE'\n",
    "    #     })\n",
    "    #     print(f\"  ‚ùå No suitable GFP range found\")\n",
    "\n",
    "\n",
    "# Summary of GFP filtering results\n",
    "# results_df = pd.DataFrame(gfp_filtered_results)\n",
    "# successful_pairs = results_df[results_df['status'] == 'SUCCESS']\n",
    "\n",
    "# print(f\"\\n=== GFP FILTERING SUMMARY ===\")\n",
    "# print(f\"Successful pairs: {len(successful_pairs)}/{len(test_pairs)}\")\n",
    "# if len(successful_pairs) > 0:\n",
    "#     print(f\"Total cells retained: {successful_pairs['ref_filtered'].sum() + successful_pairs['var_filtered'].sum():,}\")\n",
    "#     print(f\"Average cells per successful pair: {(successful_pairs['ref_filtered'].sum() + successful_pairs['var_filtered'].sum())/len(successful_pairs):.0f}\")\n",
    "#     print(f\"Quantile ranges used: {successful_pairs['quantile_range'].value_counts().to_dict()}\")\n",
    "#     print(successful_pairs[['pair_id', 'ref_filtered', 'var_filtered', 'quantile_range']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>t_stat</th><th>p_val</th><th>cohen_d</th><th>Gene</th><th>Variant</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2.480452</td><td>0.131276</td><td>0.938714</td><td>&quot;CCM2&quot;</td><td>&quot;CCM2_Val53Ile&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ t_stat   ‚îÜ p_val    ‚îÜ cohen_d  ‚îÜ Gene ‚îÜ Variant       ‚îÇ\n",
       "‚îÇ ---      ‚îÜ ---      ‚îÜ ---      ‚îÜ ---  ‚îÜ ---           ‚îÇ\n",
       "‚îÇ f64      ‚îÜ f64      ‚îÜ f64      ‚îÜ str  ‚îÜ str           ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 2.480452 ‚îÜ 0.131276 ‚îÜ 0.938714 ‚îÜ CCM2 ‚îÜ CCM2_Val53Ile ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_exp_combined_well_filtered = pl.DataFrame(\n",
    "    pd.concat(gfp_filtered_results, axis=0)\n",
    ").group_by(\n",
    "    [\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_gene_allele\"]\n",
    ").agg(\n",
    "    pl.col(col).median().alias(col)\n",
    "    for col in df_exp_combined.columns\n",
    "    if not col.startswith(\"Metadata_\")\n",
    ").unique() # .filter(pl.col(\"Metadata_gene_allele\").is_in(balanced_class_alleles))\n",
    "\n",
    "df_exp_combined_well_filtered\n",
    "\n",
    "display(paired_ttest(\n",
    "    df_exp_combined_well_filtered.filter(pl.col(\"Metadata_Well\").is_in([\"I21\", \"M19\"])).to_pandas(), \n",
    "    \"CCM2\", TARGET_ALLELE, GFP_INTENSITY_COLUMN\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLASSIFICATION] Running classification test using classify_gfp_filtered.py functions...\n",
      "Testing pair: 2025_06_02_B18A8A10R1_P2T4_I21_vs_M19\n",
      "‚ùå Error running classification: classifier_gfp_filtered() takes from 2 to 3 positional arguments but 6 were given\n",
      "The classification function may need to be implemented in classify_gfp_filtered.py\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run classification using functions from classify_gfp_filtered.py\n",
    "\n",
    "# Import classification functions we need\n",
    "from classify_gfp_filtered import (\n",
    "    classifier_gfp_filtered,\n",
    "    # get_well_pairs\n",
    ")\n",
    "\n",
    "if len(successful_pairs) > 0:\n",
    "    print(\"[CLASSIFICATION] Running classification test using classify_gfp_filtered.py functions...\")\n",
    "    \n",
    "    # Get first successful pair info\n",
    "    first_pair = successful_pairs.iloc[0]\n",
    "    print(f\"Testing pair: {first_pair['pair_id']}\")\n",
    "    \n",
    "    # Use the actual classification function from the script\n",
    "    try:\n",
    "        result = classifier_gfp_filtered(\n",
    "            df_reference_cc, df_variant_cc,\n",
    "            first_pair['plate'], first_pair['ref_well'], first_pair['var_well'],\n",
    "            MIN_CELLS_PER_WELL\n",
    "        )\n",
    "        \n",
    "        if result is not None:\n",
    "            print(f\"\\nüéØ CLASSIFICATION RESULTS\")\n",
    "            print(f\"Pair ID: {result['pair_id']}\")\n",
    "            print(f\"AUROC: {result['auroc']:.4f}\")\n",
    "            print(f\"Cells used: {result['ref_cells']} ref, {result['var_cells']} var\")\n",
    "            print(f\"GFP range: {result['gfp_range']}\")\n",
    "            print(f\"Quantile range: {result['quantile_range']}\")\n",
    "            print(f\"\\n‚úÖ Classification test completed successfully!\")\n",
    "        else:\n",
    "            print(\"‚ùå Classification failed - check the function implementation\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running classification: {e}\")\n",
    "        print(\"The classification function may need to be implemented in classify_gfp_filtered.py\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No successful pairs found - cannot run classification test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Classification Pipeline Testing\n",
    "\n",
    "Now let's test the full classification pipeline using functions from classify_gfp_filtered.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The classification pipeline testing is now complete! You can:\n",
    "\n",
    "1. **Run the full pipeline**: Use `classify_gfp_filtered.py` to process all well pairs\n",
    "2. **Optimize parameters**: Adjust `MIN_CELLS_PER_WELL`, `CC_THRESHOLD`, or quantile ranges\n",
    "3. **Analyze results**: Review classification performance and feature importance\n",
    "4. **Scale up**: Process additional alleles or batches using the same approach\n",
    "\n",
    "The GFP-filtered classification approach shows promise for improving variant discrimination by focusing on cells with similar protein expression levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varchamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
